{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04c8456e-a7b8-487f-a49e-e00fea2d9d06",
   "metadata": {},
   "source": [
    "# Battle annotation\n",
    "\n",
    "This notebook allows to annotate battle preference data from LMSys and ComparIA.\n",
    "\n",
    "TODO:\n",
    "* store annotations to huggingface dataset\n",
    "* store annotations by user/date or something\n",
    "* SAFE mode to avoid overriding previous annotations\n",
    "\n",
    "\n",
    "Done:\n",
    "* Load data from LMSys, ComparIA\n",
    "* Nice displayier\n",
    "* Store annotations\n",
    "* Compute annotator agreement rate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d74b72a-ff97-4061-8d3c-a68bdc82cdc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from fast_langdetect import detect_language\n",
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from huggingface_hub import snapshot_download\n",
    "from IPython.display import Markdown as md\n",
    "from ipywidgets import IntSlider, RadioButtons, VBox, Output\n",
    "from IPython.display import display, clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab2780c4-779b-4560-b3e4-661f704a99bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37401f8a6e72417bb4b115f1614b117d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (incomplete total...): 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22ce3b9684494bd6bb85b6059a7a18a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bd3a562967245c0aca3fad839985cff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (incomplete total...): 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3543df546ffb4807927240e8c86db585",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 6 files:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# we fix the version as comparia is continuously increasing\n",
    "def load_df(\n",
    "    comparia_revision: str = \"538ead8c4dad4ff905cd2f11d7381d7df03d3fdc\",\n",
    ") -> pd.DataFrame:\n",
    "    # load LMSys\n",
    "    path = snapshot_download(\n",
    "        repo_id=\"lmarena-ai/arena-human-preference-100k\",\n",
    "        repo_type=\"dataset\",\n",
    "        allow_patterns=\"*parquet\",\n",
    "        force_download=False,\n",
    "    )\n",
    "    df_lmsys = pd.read_parquet(\n",
    "        Path(path) / \"data\" / \"arena-explorer-preference-100k.parquet\"\n",
    "    )\n",
    "    df_lmsys[\"date\"] = pd.to_datetime(df_lmsys[\"tstamp\"], unit=\"s\")\n",
    "    df_lmsys[\"benchmark\"] = \"LMSys\"\n",
    "\n",
    "    # load ComparIA\n",
    "    path = snapshot_download(\n",
    "        repo_id=\"ministere-culture/comparia-votes\",\n",
    "        repo_type=\"dataset\",\n",
    "        allow_patterns=\"*\",\n",
    "        revision=comparia_revision,\n",
    "        force_download=False,\n",
    "    )\n",
    "\n",
    "    df_comparia = pd.read_parquet(Path(path) / \"votes.parquet\")\n",
    "\n",
    "    # unify schema\n",
    "    df_comparia[\"tstamp\"] = df_comparia[\"timestamp\"]\n",
    "    df_comparia[\"model_a\"] = df_comparia[\"model_a_name\"]\n",
    "    df_comparia[\"model_b\"] = df_comparia[\"model_b_name\"]\n",
    "\n",
    "    def get_winner(\n",
    "        chosen_model_name: str, model_a: str, model_b: str, both_equal: bool, **kwargs\n",
    "    ):\n",
    "        if both_equal or chosen_model_name is None:\n",
    "            return \"tie\"\n",
    "        else:\n",
    "            assert chosen_model_name in [\n",
    "                model_a,\n",
    "                model_b,\n",
    "            ], f\"Chosen model: {chosen_model_name} but model_a: {model_a} and model_b: {model_b}\"\n",
    "            return \"model_a\" if chosen_model_name == model_a else \"model_b\"\n",
    "\n",
    "    df_comparia[\"winner\"] = df_comparia.apply(lambda row: get_winner(**row), axis=1)\n",
    "    df_comparia[\"benchmark\"] = \"ComparIA\"\n",
    "    df_comparia[\"question_id\"] = df_comparia[\"id\"]\n",
    "    cols = [\n",
    "        \"question_id\",\n",
    "        \"tstamp\",\n",
    "        \"model_a\",\n",
    "        \"model_b\",\n",
    "        \"winner\",\n",
    "        \"conversation_a\",\n",
    "        \"conversation_b\",\n",
    "        \"benchmark\",\n",
    "    ]\n",
    "    df = pd.concat([df_lmsys.loc[:, cols], df_comparia.loc[:, cols]], ignore_index=True)\n",
    "\n",
    "    # keep only one turn conversation for now as they are easier to evaluate\n",
    "    df[\"turns\"] = df.apply(lambda row: len(row[\"conversation_a\"]) - 1, axis=1)\n",
    "    df = df.loc[df.turns == 1]\n",
    "\n",
    "    df[\"lang\"] = df.apply(\n",
    "        lambda row: detect_language(row[\"conversation_a\"][0][\"content\"]).lower(), axis=1\n",
    "    )\n",
    "\n",
    "    return df\n",
    "    \n",
    "df = load_df()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9943d9f8-a9d0-4812-9b40-af06ca9ab99f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-02T17:27:13.144853Z",
     "start_time": "2025-12-02T17:27:12.640727Z"
    }
   },
   "outputs": [],
   "source": [
    "# select language\n",
    "language = \"fr\"\n",
    "n_instructions = 100\n",
    "\n",
    "# fix the sampling seed\n",
    "seed = 0\n",
    "\n",
    "df_lmsys = df.loc[(df[\"lang\"] == language) & (df[\"benchmark\"] == \"LMSys\") & (df[\"turns\"] == 1)]\n",
    "df_comparia = df.loc[(df[\"lang\"] == language) & (df[\"benchmark\"] == \"ComparIA\") & (df[\"turns\"] == 1)]\n",
    "\n",
    "# sample n // 2 for each source of battles\n",
    "df_sample = pd.concat([\n",
    "    df_lmsys.sample(\n",
    "        n=n_instructions // 2, random_state=seed\n",
    "    ),\n",
    "    df_comparia.sample(\n",
    "        n=n_instructions // 2, random_state=seed\n",
    "    ),\n",
    "], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bad6a702-0ed1-45ea-90d0-92dffa3f7dcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_id</th>\n",
       "      <th>tstamp</th>\n",
       "      <th>model_a</th>\n",
       "      <th>model_b</th>\n",
       "      <th>winner</th>\n",
       "      <th>conversation_a</th>\n",
       "      <th>conversation_b</th>\n",
       "      <th>benchmark</th>\n",
       "      <th>turns</th>\n",
       "      <th>lang</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>f20f0c2b58264167a1f4921d2133e65d</td>\n",
       "      <td>1723120202.3584</td>\n",
       "      <td>gemini-1.5-pro-exp-0801</td>\n",
       "      <td>mistral-large-2407</td>\n",
       "      <td>model_a</td>\n",
       "      <td>[{'content': 'Gary est 2eme, Tom 3eme, Bryan 4...</td>\n",
       "      <td>[{'content': 'Gary est 2eme, Tom 3eme, Bryan 4...</td>\n",
       "      <td>LMSys</td>\n",
       "      <td>1</td>\n",
       "      <td>fr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6aa4e5eac2344dc194eec35abc491c69</td>\n",
       "      <td>1724052360.0131</td>\n",
       "      <td>gemma-2-2b-it</td>\n",
       "      <td>gemma-2-9b-it-simpo</td>\n",
       "      <td>tie</td>\n",
       "      <td>[{'content': 'Imagine je gagne 900‚Ç¨ tous les d...</td>\n",
       "      <td>[{'content': 'Imagine je gagne 900‚Ç¨ tous les d...</td>\n",
       "      <td>LMSys</td>\n",
       "      <td>1</td>\n",
       "      <td>fr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>48db42c40fd94ec9a1f21a707df6561c</td>\n",
       "      <td>1719143875.9731</td>\n",
       "      <td>gemini-1.5-flash-api-0514</td>\n",
       "      <td>gemini-1.5-pro-api-0514</td>\n",
       "      <td>model_b</td>\n",
       "      <td>[{'content': 'Invente une technologie qui n'ex...</td>\n",
       "      <td>[{'content': 'Invente une technologie qui n'ex...</td>\n",
       "      <td>LMSys</td>\n",
       "      <td>1</td>\n",
       "      <td>fr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35c926b6ac2e408d9f9c0b8e021e966f</td>\n",
       "      <td>1723531827.1816</td>\n",
       "      <td>chatgpt-4o-latest</td>\n",
       "      <td>mistral-large-2407</td>\n",
       "      <td>model_b</td>\n",
       "      <td>[{'content': '[Couplet 1]\n",
       "Dans les immeubles o...</td>\n",
       "      <td>[{'content': '[Couplet 1]\n",
       "Dans les immeubles o...</td>\n",
       "      <td>LMSys</td>\n",
       "      <td>1</td>\n",
       "      <td>fr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>73526597a769431380ea3d712153f408</td>\n",
       "      <td>1721552250.6168</td>\n",
       "      <td>mixtral-8x22b-instruct-v0.1</td>\n",
       "      <td>claude-3-5-sonnet-20240620</td>\n",
       "      <td>tie</td>\n",
       "      <td>[{'content': 'Je viens de d√©couvrir la cha√Æne ...</td>\n",
       "      <td>[{'content': 'Je viens de d√©couvrir la cha√Æne ...</td>\n",
       "      <td>LMSys</td>\n",
       "      <td>1</td>\n",
       "      <td>fr</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        question_id           tstamp  \\\n",
       "0  f20f0c2b58264167a1f4921d2133e65d  1723120202.3584   \n",
       "1  6aa4e5eac2344dc194eec35abc491c69  1724052360.0131   \n",
       "2  48db42c40fd94ec9a1f21a707df6561c  1719143875.9731   \n",
       "3  35c926b6ac2e408d9f9c0b8e021e966f  1723531827.1816   \n",
       "4  73526597a769431380ea3d712153f408  1721552250.6168   \n",
       "\n",
       "                       model_a                     model_b   winner  \\\n",
       "0      gemini-1.5-pro-exp-0801          mistral-large-2407  model_a   \n",
       "1                gemma-2-2b-it         gemma-2-9b-it-simpo      tie   \n",
       "2    gemini-1.5-flash-api-0514     gemini-1.5-pro-api-0514  model_b   \n",
       "3            chatgpt-4o-latest          mistral-large-2407  model_b   \n",
       "4  mixtral-8x22b-instruct-v0.1  claude-3-5-sonnet-20240620      tie   \n",
       "\n",
       "                                      conversation_a  \\\n",
       "0  [{'content': 'Gary est 2eme, Tom 3eme, Bryan 4...   \n",
       "1  [{'content': 'Imagine je gagne 900‚Ç¨ tous les d...   \n",
       "2  [{'content': 'Invente une technologie qui n'ex...   \n",
       "3  [{'content': '[Couplet 1]\n",
       "Dans les immeubles o...   \n",
       "4  [{'content': 'Je viens de d√©couvrir la cha√Æne ...   \n",
       "\n",
       "                                      conversation_b benchmark  turns lang  \n",
       "0  [{'content': 'Gary est 2eme, Tom 3eme, Bryan 4...     LMSys      1   fr  \n",
       "1  [{'content': 'Imagine je gagne 900‚Ç¨ tous les d...     LMSys      1   fr  \n",
       "2  [{'content': 'Invente une technologie qui n'ex...     LMSys      1   fr  \n",
       "3  [{'content': '[Couplet 1]\n",
       "Dans les immeubles o...     LMSys      1   fr  \n",
       "4  [{'content': 'Je viens de d√©couvrir la cha√Æne ...     LMSys      1   fr  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c605572-878e-4a34-a70c-eae4ab195979",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize annotations dictionary\n",
    "# WARNING: if you rerun this cell you will loose your annotations\n",
    "annotations = {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b1f9fb6a-b34e-461b-9f2a-a088e70136aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7d5f31deed14786a877a952a7b73b9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(IntSlider(value=0, continuous_update=False, description='Record:', layout=Layout(width='500px')‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74380f97701a4d6da11ab52eab4edf18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create output widget for displaying records\n",
    "output = Output()\n",
    "\n",
    "# Create slider with step buttons enabled\n",
    "slider = IntSlider(\n",
    "    min=0, \n",
    "    max=len(df_sample) - 1, \n",
    "    step=1, \n",
    "    value=0, \n",
    "    description='Record:', \n",
    "    style={'description_width': 'initial'},\n",
    "    layout={'width': '500px'},\n",
    "    continuous_update=False  # Only update when you release or use arrow buttons\n",
    ")\n",
    "\n",
    "# Create radio buttons\n",
    "radio = RadioButtons(\n",
    "    options=['Not annotated', 'Model A', 'Tie', 'Model B'],\n",
    "    value='Not annotated',\n",
    "    description='Your choice:',\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "\n",
    "def show_record(i: int):\n",
    "    with output:\n",
    "        clear_output(wait=True)\n",
    "        \n",
    "        print(f\"üìä **Record {i}**\")    \n",
    "\n",
    "        # Show annotation status\n",
    "        current_annotation = annotations.get(i, 'Not annotated')\n",
    "        print(f\"‚úÖ Current annotation: {current_annotation}\")\n",
    "        #print(f\"üìà Total annotated: {len([a for a in annotations.values() if a != 'Not annotated'])} / {len(df_sample)}\")\n",
    "        print(f\"üìà Total annotated: {len(annotations)} / {len(df_sample)}\")\n",
    "\n",
    "\n",
    "        #print(f\"üîç Benchmark: {df_sample.loc[i, 'benchmark']}\")\n",
    "        conv_a = df_sample.loc[i, \"conversation_a\"]\n",
    "        conv_b = df_sample.loc[i, \"conversation_b\"]\n",
    "        \n",
    "        print(f'\\n\\033[1müìù Instruction:\\033[0m\\n{conv_a[0][\"content\"]}')\n",
    "        print(f\"\\n\\033[1müí¨ Completion A:\\033[0m\\n{conv_a[1][\"content\"]}\")\n",
    "        print(f\"\\n{'-'*80}\")\n",
    "        print(f\"\\n\\033[1müí¨ Completion B:\\033[0m\\n{conv_b[1][\"content\"]}\")\n",
    "        print(f\"\\n{'='*80}\\n\")\n",
    "        \n",
    "\n",
    "def on_slider_change(change):\n",
    "    i = change['new']\n",
    "    # Load the annotation for this record\n",
    "    radio.value = annotations.get(i, 'Not annotated')\n",
    "    show_record(i)\n",
    "\n",
    "def on_radio_change(change):\n",
    "    i = slider.value\n",
    "    annotations[i] = change['new']\n",
    "    show_record(i)\n",
    "\n",
    "# Attach event handlers\n",
    "slider.observe(on_slider_change, names='value')\n",
    "radio.observe(on_radio_change, names='value')\n",
    "\n",
    "# Create layout\n",
    "controls = VBox([slider, radio])\n",
    "\n",
    "# Display everything\n",
    "display(controls)\n",
    "display(output)\n",
    "\n",
    "# Show initial record\n",
    "show_record(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cbea093e-39c9-4efd-9a98-844041c5aa5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!cp annotations/battles-sampled-en.csv annotations/11-28-battles-sampled-en.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c83d28b2-d53a-4645-94f1-8c174e41c520",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annotations still missing: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Annotations still missing: {list(set(range(100)).difference(set(annotations_series.index)))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa0432a1-9f93-4d3a-808f-5095021bc960",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save annotations\n",
    "from pathlib import Path\n",
    "annotation_path = Path(\"annotations\")\n",
    "annotation_path.mkdir(exist_ok=True)\n",
    "annotations_series = pd.Series(annotations)\n",
    "annotations_series.to_csv(f\"annotations/annotations-{language}.csv\")\n",
    "df_sample.to_csv(f\"annotations/battles-sampled-{language}.csv\", index=False)\n",
    "annotations_series.value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
