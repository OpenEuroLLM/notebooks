{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd98c03d-034c-424d-8bca-0d7adaad3cec",
   "metadata": {},
   "source": [
    "This notebook shows some metrics regarding annotated data from a user.\n",
    "\n",
    "It shows Cohen-Kappa and also allow to interactively display cases with disagreement.\n",
    "\n",
    "\n",
    "```\n",
    "TODOs:\n",
    "Done:\n",
    "* load annotated data\n",
    "* compute cohen-kappa\n",
    "* plot disagreement\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a249452e-6b4d-420d-837b-4128a46c7912",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from huggingface_hub import snapshot_download\n",
    "from ast import literal_eval\n",
    "import re\n",
    "from IPython.display import Markdown as md, display, clear_output\n",
    "from ipywidgets import interact, IntSlider\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a80cf269-a89a-4399-812a-958c70869df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "language = \"en\"\n",
    "user = \"salinasd\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f91dc93-e9b4-4169-9442-3dc9d314ba2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00ab54d763994b9bad6a2788f025842c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (incomplete total...): 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de7260b639004a9f9b3f8da377962f7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>i</th>\n",
       "      <th>annotation</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>question_id</th>\n",
       "      <th>model_a</th>\n",
       "      <th>model_b</th>\n",
       "      <th>winner</th>\n",
       "      <th>benchmark</th>\n",
       "      <th>conversation_a</th>\n",
       "      <th>conversation_b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>model_b</td>\n",
       "      <td>2025-10-12T03:40:14.792200</td>\n",
       "      <td>ad26e8112d694b9bbb9896aa29c239b9</td>\n",
       "      <td>gemini-1.5-flash-api-0514</td>\n",
       "      <td>deepseek-v2-api-0628</td>\n",
       "      <td>model_b</td>\n",
       "      <td>LMSys</td>\n",
       "      <td>[{'content': 'explain the Boston tea party in ...</td>\n",
       "      <td>[{'content': 'explain the Boston tea party in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>model_b</td>\n",
       "      <td>2025-10-12T03:40:14.792200</td>\n",
       "      <td>e828bb4e824e49fdb680a17854a6fc29</td>\n",
       "      <td>deepseek-coder-v2</td>\n",
       "      <td>phi-3-mini-4k-instruct-june-2024</td>\n",
       "      <td>model_b</td>\n",
       "      <td>LMSys</td>\n",
       "      <td>[{'content': '9.11 and 9.9 - which is bigger',...</td>\n",
       "      <td>[{'content': '9.11 and 9.9 - which is bigger',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>model_b</td>\n",
       "      <td>2025-10-12T03:40:14.792200</td>\n",
       "      <td>c1651f3d73c74b50b8bde1eac4c4e089</td>\n",
       "      <td>qwen2-72b-instruct</td>\n",
       "      <td>glm-4-0520</td>\n",
       "      <td>tie</td>\n",
       "      <td>LMSys</td>\n",
       "      <td>[{'content': 'My teammate used a phrase \"–∂—ë–≤–∞–Ω...</td>\n",
       "      <td>[{'content': 'My teammate used a phrase \"–∂—ë–≤–∞–Ω...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>tie</td>\n",
       "      <td>2025-10-12T03:40:14.792200</td>\n",
       "      <td>df75e5cb38df4572a7bd3a0e4432dd85</td>\n",
       "      <td>reka-flash-20240722</td>\n",
       "      <td>claude-3-5-sonnet-20240620</td>\n",
       "      <td>tie</td>\n",
       "      <td>LMSys</td>\n",
       "      <td>[{'content': 'get file folder python', 'num_to...</td>\n",
       "      <td>[{'content': 'get file folder python', 'num_to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>tie</td>\n",
       "      <td>2025-10-12T03:40:14.792200</td>\n",
       "      <td>9f2fbba8e6cb47a08cedf89d545044ab</td>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>gpt-4o-mini-2024-07-18</td>\n",
       "      <td>tie</td>\n",
       "      <td>LMSys</td>\n",
       "      <td>[{'content': 'Hello', 'num_tokens': 1, 'role':...</td>\n",
       "      <td>[{'content': 'Hello', 'num_tokens': 1, 'role':...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   i annotation                   timestamp                       question_id  \\\n",
       "0  0    model_b  2025-10-12T03:40:14.792200  ad26e8112d694b9bbb9896aa29c239b9   \n",
       "2  1    model_b  2025-10-12T03:40:14.792200  e828bb4e824e49fdb680a17854a6fc29   \n",
       "3  2    model_b  2025-10-12T03:40:14.792200  c1651f3d73c74b50b8bde1eac4c4e089   \n",
       "5  5        tie  2025-10-12T03:40:14.792200  df75e5cb38df4572a7bd3a0e4432dd85   \n",
       "6  6        tie  2025-10-12T03:40:14.792200  9f2fbba8e6cb47a08cedf89d545044ab   \n",
       "\n",
       "                     model_a                           model_b   winner  \\\n",
       "0  gemini-1.5-flash-api-0514              deepseek-v2-api-0628  model_b   \n",
       "2          deepseek-coder-v2  phi-3-mini-4k-instruct-june-2024  model_b   \n",
       "3         qwen2-72b-instruct                        glm-4-0520      tie   \n",
       "5        reka-flash-20240722        claude-3-5-sonnet-20240620      tie   \n",
       "6         gpt-4-1106-preview            gpt-4o-mini-2024-07-18      tie   \n",
       "\n",
       "  benchmark                                     conversation_a  \\\n",
       "0     LMSys  [{'content': 'explain the Boston tea party in ...   \n",
       "2     LMSys  [{'content': '9.11 and 9.9 - which is bigger',...   \n",
       "3     LMSys  [{'content': 'My teammate used a phrase \"–∂—ë–≤–∞–Ω...   \n",
       "5     LMSys  [{'content': 'get file folder python', 'num_to...   \n",
       "6     LMSys  [{'content': 'Hello', 'num_tokens': 1, 'role':...   \n",
       "\n",
       "                                      conversation_b  \n",
       "0  [{'content': 'explain the Boston tea party in ...  \n",
       "2  [{'content': '9.11 and 9.9 - which is bigger',...  \n",
       "3  [{'content': 'My teammate used a phrase \"–∂—ë–≤–∞–Ω...  \n",
       "5  [{'content': 'get file folder python', 'num_to...  \n",
       "6  [{'content': 'Hello', 'num_tokens': 1, 'role':...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = snapshot_download(\n",
    "    repo_id=\"openeurollm/battle-annotations\",\n",
    "    repo_type=\"dataset\",\n",
    "    allow_patterns=\"*parquet\",\n",
    "    force_download=False,\n",
    ")\n",
    "df = pd.read_parquet(Path(path) / f\"{user}_{language}.parquet\")\n",
    "\n",
    "# align names\n",
    "df[\"annotation\"] = df[\"annotation\"].apply(lambda s: s.replace(\"Model B\", \"model_b\").replace(\"Model A\", \"model_a\").replace(\"Tie\", \"tie\"))\n",
    "df[\"winner\"] = df[\"winner\"].apply(lambda s: s.replace(\"tie (bothbad)\", \"tie\"))\n",
    "# skip instructions not annotated\n",
    "df = df[df.annotation != \"Not annotated\"]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe3bcb57-9387-4bb9-9a5c-73bbbdf3c3ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.47435897435897434)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df.annotation == df.winner).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1e7151b0-a1b2-4168-9425-babf2cfd8412",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.18418367346938777"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def compute_cohen_kappa(y1: list[str], y2: list[str]) -> float:\n",
    "    \"\"\"\n",
    "    Compute Cohen's kappa coefficient for inter-rater agreement.\n",
    "\n",
    "    Args:\n",
    "        y1: List of labels from first rater\n",
    "        y2: List of labels from second rater\n",
    "\n",
    "    Returns:\n",
    "        Cohen's kappa coefficient (float between -1 and 1)\n",
    "    \"\"\"\n",
    "    if len(y1) != len(y2):\n",
    "        raise ValueError(\"Both lists must have the same length\")\n",
    "\n",
    "    if len(y1) == 0:\n",
    "        raise ValueError(\"Lists cannot be empty\")\n",
    "\n",
    "    # Get all unique categories\n",
    "    categories = sorted(set(y1) | set(y2))\n",
    "    n = len(y1)\n",
    "\n",
    "    # Build confusion matrix\n",
    "    matrix = {}\n",
    "    for cat1 in categories:\n",
    "        matrix[cat1] = {cat2: 0 for cat2 in categories}\n",
    "\n",
    "    for label1, label2 in zip(y1, y2):\n",
    "        matrix[label1][label2] += 1\n",
    "\n",
    "    # Compute observed agreement (p_o)\n",
    "    observed_agreement = sum(matrix[cat][cat] for cat in categories) / n\n",
    "\n",
    "    # Compute expected agreement (p_e)\n",
    "    expected_agreement = 0\n",
    "    for cat in categories:\n",
    "        # Marginal probabilities\n",
    "        p1 = sum(matrix[cat][c] for c in categories) / n  # rater 1\n",
    "        p2 = sum(matrix[c][cat] for c in categories) / n  # rater 2\n",
    "        expected_agreement += p1 * p2\n",
    "\n",
    "    # Compute Cohen's kappa\n",
    "    if expected_agreement == 1:\n",
    "        return 1.0 if observed_agreement == 1 else 0.0\n",
    "\n",
    "    kappa = (observed_agreement - expected_agreement) / (1 - expected_agreement)\n",
    "\n",
    "    return kappa\n",
    "\n",
    "compute_cohen_kappa(df.annotation, df.winner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "660c0938-c732-4cd2-93aa-838f6421ef02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show disagreements\n",
    "df_disagreement = df[df.annotation != df.winner]\n",
    "len(df_disagreement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "92fd5f77-9781-4173-9154-0a520278d9fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d95d641f044e42cf81fb0b217074c831",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='Index:', max=40), Output()), _dom_classes=('widget-inter‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.show_record(i: int)>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def show_record(i: int):\n",
    "    row = df_disagreement.reset_index().loc[i].to_dict()\n",
    "    \n",
    "    # Get question_id for current record\n",
    "    question_id = row['question_id']\n",
    "    \n",
    "    annotation = f'Benchmark choice: **{row[\"winner\"]}**\\nYour choice: **{row[\"annotation\"]}**'\n",
    "\n",
    "    conv_a = re.sub(r'\\}\\s*\\{', '}, {', row[\"conversation_a\"])\n",
    "    conv_b = re.sub(r'\\}\\s*\\{', '}, {', row[\"conversation_b\"])\n",
    "\n",
    "    conv_a = literal_eval(conv_a)\n",
    "    conv_b = literal_eval(conv_b)\n",
    "\n",
    "    # Build the full markdown string\n",
    "    markdown_content = f\"\"\"\n",
    "#### üìä Record {i}\n",
    "\n",
    "{annotation}\n",
    "\n",
    "---\n",
    "\n",
    "#### üìù Instruction\n",
    "\n",
    "{conv_a[0][\"content\"]}\n",
    "\n",
    "---\n",
    "\n",
    "#### üí¨ Completion A\n",
    "\n",
    "{conv_a[1][\"content\"]}\n",
    "\n",
    "---\n",
    "\n",
    "#### üí¨ Completion B\n",
    "\n",
    "{conv_b[1][\"content\"]}\n",
    "\n",
    "---\n",
    "\"\"\"\n",
    "    display(md(markdown_content))\n",
    "\n",
    "# Interactive widget - adjust max value based on your dataframe size\n",
    "interact(\n",
    "    show_record,\n",
    "    i=IntSlider(min=0, max=len(df_disagreement)-1, step=1, value=0, description='Index:')\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
